{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setGPU: Setting GPU to: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import setGPU\n",
    "import nn_utils.misc.keras_not_full_memory_importer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import inspect\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import os.path as osp\n",
    "import imageio as imio\n",
    "import minimg\n",
    "import copy\n",
    "import cv2\n",
    "from skimage.color import rgb2gray\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.callbacks import Callback, ModelCheckpoint, TensorBoard\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras import backend as K, regularizers\n",
    "\n",
    "from metrics import *\n",
    "from uqim_utils import getUIQM\n",
    "\n",
    "#from Tensorflow.KiHoughTF import KiHoughLayerTF\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import minimg\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FRAGMENT_SIZE = 512\n",
    "BS = 4\n",
    "REG_PARAM = 0.000025\n",
    "MAX_NUM_EPOCHS = 100\n",
    "INITIAL_LEARNING_RATE = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"data/81k_preprocessed_glare\"\n",
    "name = \"exp_bibr\"\n",
    "output_dir = \"nn_weights\"\n",
    "output_nn_dir = osp.join(output_dir, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_loss(y_true, y_pred):\n",
    "    y_t = K.flatten(y_true)\n",
    "    y_p = K.flatten(y_pred)\n",
    "    delta1 = y_t - y_p\n",
    "    k1 = tf.math.multiply(delta1, delta1)\n",
    "    return K.sum(k1) \n",
    "\n",
    "def mse_loss(y_true, y_pred):\n",
    "    return tf.reduce_mean(tf.keras.losses.MSE(y_true, y_pred))\n",
    "\n",
    "def mse_loss_less_zero(y_true, y_pred):\n",
    "    tr = np.zeros((FRAGMENT_SIZE, FRAGMENT_SIZE, 3))\n",
    "    return tf.reduce_mean(tf.keras.losses.MSE(tr, y_pred))\n",
    "\n",
    "def ssim_mse(y_true, y_pred):\n",
    "        return tf.reduce_mean(tf.keras.losses.MSE(y_true, y_pred)) + (1. - tf.image.ssim(y_true, y_pred, 1.0)) * 0.25\n",
    "\n",
    "def ssim_loss(y_true, y_pred):\n",
    "    return (1. - tf.image.ssim(y_true, y_pred, 1.0))\n",
    "\n",
    "def mse_cff(y_true, y_pred):\n",
    "    c = tf.make_tensor_proto(y_pred[0])\n",
    "    return tf.reduce_mean(tf.keras.losses.MSE(y_true, y_pred)) + CFF(tf.make_ndarray(c))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_conv(kernels, kernel_size = (3,3), _padding= 'same', activation=None):\n",
    "    reg_weight = REG_PARAM\n",
    "    bias_reg_weight = REG_PARAM\n",
    "    return Conv2D(kernels, kernel_size, padding = _padding, activation=activation, kernel_regularizer=regularizers.l2(reg_weight), \n",
    "                  bias_regularizer=regularizers.l2(bias_reg_weight)) \n",
    "\n",
    "def conv_with_BN_down(x, kernels, padding, kernel_size = (3,3), dropout = 0, bn=True, is_bn = True):\n",
    "    ret = simple_conv(kernels, kernel_size, _padding = padding, activation = None)(x)\n",
    "    if is_bn:\n",
    "        ret = BatchNormalization()(ret, training=bn)\n",
    "    ret = Activation('relu')(ret)\n",
    "    ret = Dropout(dropout)(ret)\n",
    "    return ret\n",
    "\n",
    "def conv_with_BN_up(x, kernels, padding, kernel_size = (3,3), dropout = 0, bn=True, is_bn = True):\n",
    "    ret = simple_conv(kernels, kernel_size, _padding = padding, activation = None)(x)\n",
    "    if is_bn:\n",
    "        ret = BatchNormalization()(ret, training=bn)\n",
    "    ret = tf.keras.layers.LeakyReLU(alpha=0.2)(ret)\n",
    "    ret = Dropout(dropout)(ret)\n",
    "    return ret\n",
    "\n",
    "losses = {\n",
    "    \"out\": mse_loss,\n",
    "    \"lz\": mse_loss_less_zero\n",
    "}\n",
    "\n",
    "lossWeights = {\n",
    "    \"out\": 1.0,\n",
    "    \"lz\": 10.0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet_model(bn = True, pic=False, img_shape=(None, None, 3)):\n",
    "    droprate = 0.25\n",
    "    inputs = Input(img_shape)\n",
    "    #inp_bg = Input((FRAGMENT_SIZE, FRAGMENT_SIZE, 3), batch_size=BS)\n",
    "    \n",
    "    conv1 = conv_with_BN_down(inputs, 32, padding='same', dropout=droprate*0.125, is_bn=False)\n",
    "    conv1 = conv_with_BN_down(conv1, 32, padding='same', dropout=droprate*0.125, is_bn=False)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    \n",
    "    \n",
    "    conv2 = conv_with_BN_down(pool1, 64, padding='same', dropout=droprate*0.25, bn=bn)\n",
    "    conv2 = conv_with_BN_down(conv2, 64, padding='same', dropout=droprate*0.25, bn=bn)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    \n",
    "    \n",
    "    conv3 = conv_with_BN_down(pool2, 96, padding='same', dropout=droprate*0.375, bn=bn)\n",
    "    conv3 = conv_with_BN_down(conv3, 96, padding='same', dropout=droprate*0.375, bn=bn)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    \n",
    "    \n",
    "    conv4 = conv_with_BN_down(pool3, 128, padding='same', dropout=droprate*0.5, bn=bn)\n",
    "    conv4 = conv_with_BN_down(conv4, 128, padding='same', dropout=droprate*0.5, bn=bn)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "   \n",
    "    \n",
    "    conv5 = conv_with_BN_down(pool4, 160, padding='same', dropout=droprate*0.625, bn=bn)\n",
    "    conv5 = conv_with_BN_down(conv5, 160, padding='same', dropout=droprate*0.625, bn=bn)\n",
    "    pool5 = MaxPooling2D(pool_size=(2, 2))(conv5)\n",
    "    \n",
    "    \n",
    "    conv5_1 = conv_with_BN_down(pool5, 192, padding='same', dropout=droprate*0.75, bn=bn)\n",
    "    conv5_1 = conv_with_BN_down(conv5_1, 192, padding='same', dropout=droprate*0.75, bn=bn)\n",
    "    pool5_1 = MaxPooling2D(pool_size=(2, 2))(conv5_1)\n",
    "    \n",
    "    \n",
    "    conv5_2 = conv_with_BN_down(pool5_1, 224, padding='same', dropout=droprate*0.875, bn=bn)\n",
    "    conv5_2 = conv_with_BN_down(conv5_2, 224, padding='same', dropout=droprate*0.875, bn=bn)\n",
    "    pool5_2 = MaxPooling2D(pool_size=(2, 2))(conv5_2)\n",
    "    \n",
    "        \n",
    "    conv6 = conv_with_BN_down(pool5_2, 256, padding='same', dropout=droprate, bn=bn)\n",
    "    conv6 = conv_with_BN_down(conv6, 256, padding='same', dropout=droprate, bn=bn)\n",
    "    \n",
    "    \n",
    "    up7_mask_2 = Conv2DTranspose(224, (3, 3), strides=(2, 2), padding='same')(conv6)\n",
    "    if(up7_mask_2.shape[1] != conv5_2.shape[1]):\n",
    "        up7_mask_2 = ZeroPadding2D(padding=((0, 1),(0, 0)))(up7_mask_2)\n",
    "    if(up7_mask_2.shape[2] != conv5_2.shape[2]):\n",
    "        up7_mask_2 = ZeroPadding2D(padding=((0, 0),(0, 1)))(up7_mask_2)\n",
    "    up7_mask_2 = concatenate([up7_mask_2, conv5_2], axis=-1)\n",
    "    conv7_mask_2 = conv_with_BN_up(up7_mask_2, 224, padding='same', dropout=droprate*0.875, bn=bn)\n",
    "    conv7_mask_2 = conv_with_BN_up(conv7_mask_2, 224, padding='same', dropout=droprate*0.875, bn=bn)\n",
    "    \n",
    "    if(pic):\n",
    "        up7_pic_2 = Conv2DTranspose(224, (3, 3), strides=(2, 2), padding='same')(conv6)\n",
    "        if(up7_pic_2.shape[1] != conv5_2.shape[1]):\n",
    "            up7_pic_2 = ZeroPadding2D(padding=((0, 1),(0, 0)))(up7_pic_2)\n",
    "        if(up7_pic_2.shape[2] != conv5_2.shape[2]):\n",
    "            up7_pic_2 = ZeroPadding2D(padding=((0, 0),(0, 1)))(up7_pic_2)\n",
    "        up7_pic_2 = concatenate([up7_pic_2, conv5_2], axis=-1)\n",
    "        conv7_pic_2 = conv_with_BN_up(up7_pic_2, 224, padding='same', dropout=droprate*0.875, bn=bn)\n",
    "        conv7_pic_2 = conv_with_BN_up(conv7_pic_2, 224, padding='same', dropout=droprate*0.875, bn=bn)\n",
    "    \n",
    "    up7_mask_3 = Conv2DTranspose(192, (3, 3), strides=(2, 2), padding='same')(conv7_mask_2)\n",
    "    if(up7_mask_3.shape[1] != conv5_1.shape[1]):\n",
    "        up7_mask_3 = ZeroPadding2D(padding=((0, 1),(0, 0)))(up7_mask_3)\n",
    "    if(up7_mask_3.shape[2] != conv5_1.shape[2]):\n",
    "        up7_mask_3 = ZeroPadding2D(padding=((0, 0),(0, 1)))(up7_mask_3)\n",
    "    up7_mask_3 = concatenate([up7_mask_3, conv5_1], axis=-1)\n",
    "    conv7_mask_3 = conv_with_BN_up(up7_mask_3, 192, padding='same', dropout=droprate*0.75, bn=bn)\n",
    "    conv7_mask_3 = conv_with_BN_up(conv7_mask_3, 192, padding='same', dropout=droprate*0.75, bn=bn)\n",
    "    \n",
    "    if(pic):\n",
    "        up7_pic_3 = Conv2DTranspose(192, (3, 3), strides=(2, 2), padding='same')(conv7_pic_2)\n",
    "        if(up7_pic_3.shape[1] != conv5_1.shape[1]):\n",
    "            up7_pic_3 = ZeroPadding2D(padding=((0, 1),(0, 0)))(up7_pic_3)\n",
    "        if(up7_pic_3.shape[2] != conv5_1.shape[2]):\n",
    "            up7_pic_3 = ZeroPadding2D(padding=((0, 0),(0, 1)))(up7_pic_3)\n",
    "        up7_pic_3 = concatenate([up7_pic_3, conv5_1], axis=-1)\n",
    "        conv7_pic_3 = conv_with_BN_up(up7_pic_3, 192, padding='same', dropout=droprate*0.75, bn=bn)\n",
    "        conv7_pic_3 = conv_with_BN_up(conv7_pic_3, 192, padding='same', dropout=droprate*0.75, bn=bn)\n",
    "    \n",
    "    up7_mask = Conv2DTranspose(160, (3, 3), strides=(2, 2), padding='same')(conv7_mask_3)\n",
    "    if(up7_mask.shape[1] != conv5.shape[1]):\n",
    "        up7_mask = ZeroPadding2D(padding=((0, 1),(0, 0)))(up7_mask)\n",
    "    if(up7_mask.shape[2] != conv5.shape[2]):\n",
    "        up7_mask = ZeroPadding2D(padding=((0, 0),(0, 1)))(up7_mask)\n",
    "    up7_mask = concatenate([up7_mask, conv5], axis=-1)\n",
    "    conv7_mask = conv_with_BN_up(up7_mask, 160, padding='same', dropout=droprate*0.625, bn=bn)\n",
    "    conv7_mask = conv_with_BN_up(conv7_mask, 160, padding='same', dropout=droprate*0.625, bn=bn)\n",
    "    \n",
    "    if(pic):\n",
    "        up7_pic = Conv2DTranspose(160, (3, 3), strides=(2, 2), padding='same')(conv7_pic_3)\n",
    "        if(up7_pic.shape[1] != conv5.shape[1]):\n",
    "            up7_pic = ZeroPadding2D(padding=((0, 1),(0, 0)))(up7_pic)\n",
    "        if(up7_pic.shape[2] != conv5.shape[2]):\n",
    "            up7_pic = ZeroPadding2D(padding=((0, 0),(0, 1)))(up7_pic)\n",
    "        up7_pic = concatenate([up7_pic, conv5], axis=-1)\n",
    "        conv7_pic = conv_with_BN_up(up7_pic, 160, padding='same', dropout=droprate*0.625, bn=bn)\n",
    "        conv7_pic = conv_with_BN_up(conv7_pic, 160, padding='same', dropout=droprate*0.625, bn=bn)\n",
    "    \n",
    "    up_mask_8 = Conv2DTranspose(128, (3, 3), strides=(2, 2), padding='same')(conv7_mask)\n",
    "    if(up_mask_8.shape[1] != conv4.shape[1]):\n",
    "        up_mask_8 = ZeroPadding2D(padding=((0, 1),(0, 0)))(up_mask_8)\n",
    "    if(up_mask_8.shape[2] != conv4.shape[2]):\n",
    "        up_mask_8 = ZeroPadding2D(padding=((0, 0),(0, 1)))(up_mask_8)\n",
    "    up_mask_8 = concatenate([up_mask_8, conv4], axis=-1)\n",
    "    conv_mask_8 = conv_with_BN_up(up_mask_8, 128, padding='same', dropout=droprate*0.5, bn=bn)\n",
    "    conv_mask_8 = conv_with_BN_up(conv_mask_8, 128, padding='same', dropout=droprate*0.5, bn=bn)\n",
    "    \n",
    "    if(pic):\n",
    "        up_pic_8 = Conv2DTranspose(128, (3, 3), strides=(2, 2), padding='same')(conv7_pic)\n",
    "        if(up_pic_8.shape[1] != conv4.shape[1]):\n",
    "            up_pic_8 = ZeroPadding2D(padding=((0, 1),(0, 0)))(up_pic_8)\n",
    "        if(up_pic_8.shape[2] != conv4.shape[2]):\n",
    "            up_pic_8 = ZeroPadding2D(padding=((0, 0),(0, 1)))(up_pic_8)\n",
    "        up_pic_8 = concatenate([up_pic_8, conv4], axis=-1)\n",
    "        conv_pic_8 = conv_with_BN_up(up_pic_8, 128, padding='same', dropout=droprate*0.5, bn=bn)\n",
    "        conv_pic_8 = conv_with_BN_up(conv_pic_8, 128, padding='same', dropout=droprate*0.5, bn=bn)\n",
    "    \n",
    "    up_mask_9 = Conv2DTranspose(96, (3, 3), strides=(2, 2), padding='same')(conv_mask_8)\n",
    "    if(up_mask_9.shape[1] != conv3.shape[1]):\n",
    "        up_mask_9 = ZeroPadding2D(padding=((0, 1),(0, 0)))(up_mask_9)\n",
    "    if(up_mask_9.shape[2] != conv3.shape[2]):\n",
    "        up_mask_9 = ZeroPadding2D(padding=((0, 0),(0, 1)))(up_mask_9)\n",
    "    up_mask_9 = concatenate([up_mask_9, conv3], axis=-1)\n",
    "    conv_mask_9 = conv_with_BN_up(up_mask_9, 96, padding='same', dropout=droprate*0.375, bn=bn)\n",
    "    conv_mask_9 = conv_with_BN_up(conv_mask_9, 96, padding='same', dropout=droprate*0.375, bn=bn)\n",
    "    \n",
    "    if(pic):\n",
    "        up_pic_9 = Conv2DTranspose(96, (3, 3), strides=(2, 2), padding='same')(conv_pic_8)\n",
    "        if(up_pic_9.shape[1] != conv3.shape[1]):\n",
    "            up_pic_9 = ZeroPadding2D(padding=((0, 1),(0, 0)))(up_pic_9)\n",
    "        if(up_pic_9.shape[2] != conv3.shape[2]):\n",
    "            up_pic_9 = ZeroPadding2D(padding=((0, 0),(0, 1)))(up_pic_9)\n",
    "        up_pic_9 = concatenate([up_pic_9, conv3], axis=-1)\n",
    "        conv_pic_9 = conv_with_BN_up(up_pic_9, 96, padding='same', dropout=droprate*0.375, bn=bn)\n",
    "        conv_pic_9= conv_with_BN_up(conv_pic_9, 96, padding='same', dropout=droprate*0.375, bn=bn)\n",
    "    \n",
    "    up_mask_10 = Conv2DTranspose(64, (3, 3), strides=(2, 2), padding='same')(conv_mask_9)\n",
    "    if(up_mask_10.shape[1] != conv2.shape[1]):\n",
    "        up_mask_10 = ZeroPadding2D(padding=((0, 1),(0, 0)))(up_mask_10)\n",
    "    if(up_mask_10.shape[2] != conv2.shape[2]):\n",
    "        up_mask_10 = ZeroPadding2D(padding=((0, 0),(0, 1)))(up_mask_10)\n",
    "    up_mask_10 = concatenate([up_mask_10, conv2], axis=-1)\n",
    "    conv_mask_10 = conv_with_BN_up(up_mask_10, 64, padding='same', dropout=droprate*0.25, bn=bn)\n",
    "    conv_mask_10 = conv_with_BN_up(conv_mask_10, 64, padding='same', dropout=droprate*0.25, bn=bn)\n",
    "    \n",
    "    if(pic):\n",
    "        up_pic_10 = Conv2DTranspose(64, (3, 3), strides=(2, 2), padding='same')(conv_pic_9)\n",
    "        if(up_pic_10.shape[1] != conv2.shape[1]):\n",
    "            up_pic_10 = ZeroPadding2D(padding=((0, 1),(0, 0)))(up_pic_10)\n",
    "        if(up_pic_10.shape[2] != conv2.shape[2]):\n",
    "            up_pic_10 = ZeroPadding2D(padding=((0, 0),(0, 1)))(up_pic_10)\n",
    "        up_pic_10 = concatenate([up_pic_10, conv2], axis=-1)\n",
    "        conv_pic_10 = conv_with_BN_up(up_pic_10, 64, padding='same', dropout=droprate*0.25, bn=bn)\n",
    "        conv_pic_10= conv_with_BN_up(conv_pic_10, 64, padding='same', dropout=droprate*0.25, bn=bn)\n",
    "    \n",
    "    up_mask_11 = Conv2DTranspose(32, (3, 3), strides=(2, 2), padding='same')(conv_mask_10)\n",
    "    if(up_mask_11.shape[1] != conv1.shape[1]):\n",
    "        up_mask_11 = ZeroPadding2D(padding=((0, 1),(0, 0)))(up_mask_11)\n",
    "    if(up_mask_11.shape[2] != conv1.shape[2]):\n",
    "        up_mask_11 = ZeroPadding2D(padding=((0, 0),(0, 1)))(up_mask_11)\n",
    "    up_mask_11 = concatenate([up_mask_11, conv1], axis=-1)\n",
    "    conv_mask_11 = conv_with_BN_up(up_mask_11, 32, padding='same', dropout=droprate*0.125, is_bn=False)\n",
    "    conv_mask_11 = conv_with_BN_up(conv_mask_11, 32, padding='same', dropout=droprate*0.125, is_bn=False)\n",
    "    \n",
    "    if(pic):\n",
    "        up_pic_11 = Conv2DTranspose(32, (3, 3), strides=(2, 2), padding='same')(conv_pic_10)\n",
    "        if(up_pic_11.shape[1] != conv1.shape[1]):\n",
    "            up_pic_11 = ZeroPadding2D(padding=((0, 1),(0, 0)))(up_pic_11)\n",
    "        if(up_pic_11.shape[2] != conv1.shape[2]):\n",
    "            up_pic_11 = ZeroPadding2D(padding=((0, 0),(0, 1)))(up_pic_11)\n",
    "        up_pic_11 = concatenate([up_pic_11, conv1], axis=-1)\n",
    "        conv_pic_11 = conv_with_BN_up(up_pic_11, 32, padding='same', dropout=droprate*0.125, bn=False)\n",
    "        conv_pic_11= conv_with_BN_up(conv_pic_11, 32, padding='same', dropout=droprate*0.125, bn=False)\n",
    "    \n",
    "    \n",
    "    \n",
    "    conv_mask = Conv2D(3, (1, 1), activation='relu', kernel_regularizer=regularizers.l2(REG_PARAM), \n",
    "                       bias_regularizer=regularizers.l2(REG_PARAM))(conv_mask_11)\n",
    "    #glare_color = Conv2D(3, (1, 1), activation='sigmoid', name=\"glare_color\")(conv_mask_11)\n",
    "    \n",
    "    if(pic):\n",
    "        conv_pic = Conv2D(3, (1, 1), activation='relu', kernel_regularizer=regularizers.l2(REG_PARAM), \n",
    "                          bias_regularizer=regularizers.l2(REG_PARAM))(conv_pic_11)\n",
    "    \n",
    "    \n",
    "    \n",
    "    if(pic):\n",
    "        out = inputs - conv_mask + conv_pic\n",
    "    else:\n",
    "        out = inputs - conv_mask\n",
    "    \n",
    "    out = tf.math.maximum(out, 0.)\n",
    "    out = tf.math.minimum(out, 1.)\n",
    "    \n",
    "    out = Lambda(lambda x: x, name=\"out\")(out)\n",
    "\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=out)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not osp.exists(output_nn_dir):\n",
    "    os.mkdir(output_nn_dir)\n",
    "       \n",
    "fs = FRAGMENT_SIZE\n",
    "\n",
    "train_len = pd.read_csv(osp.join(data_path, 'train_filenames.csv')).shape[0]\n",
    "valid_len = pd.read_csv(osp.join(data_path, 'valid_filenames.csv')).shape[0]\n",
    "\n",
    "x_train = np.memmap(\n",
    "    osp.join(data_path, 'x_train.bin'), \n",
    "    dtype=np.float32, shape=(train_len, fs, fs, 3)\n",
    ") \n",
    "x_valid = np.memmap(\n",
    "    osp.join(data_path, 'x_valid.bin'), \n",
    "    dtype=np.float32, shape=(valid_len, fs, fs, 3)\n",
    ") \n",
    "y_train = np.memmap(\n",
    "    osp.join(data_path, 'y_train.bin'), \n",
    "    dtype=np.float32, shape=(train_len, fs, fs, 3)\n",
    ") \n",
    "y_valid = np.memmap(\n",
    "    osp.join(data_path, 'y_valid.bin'), \n",
    "    dtype=np.float32, shape=(valid_len, fs, fs, 3)\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_dir = osp.join(output_nn_dir, 'weights')\n",
    "if not osp.exists(weight_dir):\n",
    "    os.mkdir(weight_dir)\n",
    "weight_file = osp.join(weight_dir, \"weights-improvement-{loss:.4f}-{val_loss:.4f}.hdf5\")        \n",
    "checkpoint = ModelCheckpoint(weight_file, monitor='loss', verbose=1, save_best_only=False, save_weights_only=True, mode='min')\n",
    "my_callbacks_list = [checkpoint]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = unet_model(bn = True, pic = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"nn_weights/exp_new_with_ssim/weights/weights-improvement-0.0451-0.0397.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(lr = INITIAL_LEARNING_RATE), loss=ssim_mse)#losses, loss_weights=lossWeights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.fit(x_train ,{\"out\":y_train, \"lz\":y_train}, validation_data=(x_valid, {\"out\":y_valid, \"lz\":y_valid}), epochs=MAX_NUM_EPOCHS, shuffle=True, callbacks=my_callbacks_list, batch_size=BS)\n",
    "#model.fit(x=[x_train, y_train] , y=x_train, validation_data=([x_valid, y_valid], x_valid), epochs=MAX_NUM_EPOCHS, shuffle=True, callbacks=my_callbacks_list, batch_size=BS)\n",
    "model.fit(x_train , y_train , validation_data=(x_valid, y_valid), epochs=MAX_NUM_EPOCHS, shuffle=True, callbacks=my_callbacks_list, batch_size=BS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "model.predict(x_valid[:1, :, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[preds1, preds2] = model.predict([x_valid[:72, :, :, :], x_valid[:72, :, :, :]])\n",
    "#preds2[preds2 < 0] = 0\n",
    "preds = model.predict(x_valid[:76, :, :, :], batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (8, 8))\n",
    "plt.imshow(x_valid[num, :, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (8, 8))\n",
    "plt.imshow(y_valid[num, :, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (8, 8))\n",
    "plt.imshow(preds[num, :, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_psnr = []\n",
    "all_ssim = []\n",
    "for i in range(76):\n",
    "    all_psnr.append(calculate_psnr(x_valid[i, :, :, :] * 255, y_valid[i, :, :, :] * 255))\n",
    "    all_ssim.append(ssim(x_valid[i, :, :, :] * 255, y_valid[i, :, :, :] * 255))\n",
    "    \n",
    "print(np.mean(all_psnr))\n",
    "print(np.mean(all_ssim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(106):\n",
    "    a = imio.imread(\"real_flared_100/pic\" + str(i) + \".jpg\") / 255.\n",
    "    if( a.shape[0] <= 2000 and a.shape[1] <= 2000):\n",
    "        model = unet_model(bn = True, pic = True, img_shape=a.shape)\n",
    "        model.load_weights(\"nn_weights/arch_exp_one_branch_5_depth/weights/weights-improvement-0.0080-0.0077.hdf5\")\n",
    "        #model.load_weights(\"nn_weights/unet_glare5/weights/weights-improvement-24306.hdf5\")\n",
    "        pred= model.predict(a.reshape(1, a.shape[0], a.shape[1], a.shape[2]).astype(np.float32), batch_size=1)\n",
    "            \n",
    "        imio.imwrite(\"ch_real_temp/ch\" + str(i) + \"_x.jpg\", np.uint8(a * 255))\n",
    "        imio.imwrite(\"ch_real_temp/ch\" + str(i) + \"_pred.jpg\", np.uint8(pred[0, :, :, :] * 255))\n",
    "        #io.imwrite(\"ch_real_dark/ch\" + str(i) + \"_br1.jpg\", np.uint8(br1[0, :, :, :] * 255))\n",
    "        #io.imwrite(\"ch_real_dark/ch\" + str(i) + \"_br2.jpg\", np.uint8(br2[0, :, :, :] * 255))\n",
    "        \n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#init_usiqe = []\n",
    "pred_usiqe = []\n",
    "#init_uiqm = []\n",
    "pred_uiqm = []\n",
    "#init_cff = []\n",
    "pred_cff = []\n",
    "\n",
    "\n",
    "\n",
    "l = [6, 11, 15, 21, 26, 30, 40, 42, 46, 68, 83]\n",
    "for i in range(106):\n",
    "    if(i not in l):\n",
    "        #cur_init = imio.imread(\"ch_real_/ch\" + str(i) + \"_init.jpg\")\n",
    "        cur_pred = imio.imread(\"Underwater Image Enhancement/ICM/OutputImages/pic\" + str(i) + \"_ICM.jpg\")\n",
    "        \n",
    "        #init_usiqe.append(UCIQE(cur_init))\n",
    "        pred_usiqe.append(UCIQE(cur_pred))\n",
    "        \n",
    "        #init_uiqm.append(getUIQM(cur_init))\n",
    "        pred_uiqm.append(getUIQM(cur_pred))\n",
    "        \n",
    "        #init_cff.append(CFF(cur_init))\n",
    "        pred_cff.append(CFF(cur_pred))\n",
    "    \n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Init USIQE:\",np.mean(init_usiqe))\n",
    "print(\"Pred USIQE:\", np.mean(pred_usiqe))\n",
    "#print(\"Init UIQM:\", np.mean(init_uiqm))\n",
    "print(\"Pred UIQM:\", np.mean(pred_uiqm))\n",
    "#print(\"Init CFF:\", np.mean(init_cff))\n",
    "print(\"Pred CFF:\", np.mean(pred_cff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#init_usiqe = []\n",
    "pred_usiqe = []\n",
    "#init_uiqm = []\n",
    "pred_uiqm = []\n",
    "#init_cff = []\n",
    "pred_cff = []\n",
    "\n",
    "\n",
    "\n",
    "l = [6, 11, 15, 21, 26, 30, 40, 42, 46, 68, 83]\n",
    "for i in range(106):\n",
    "    if(i not in l):\n",
    "        #cur_init = imio.imread(\"ch_real_/ch\" + str(i) + \"_init.jpg\")\n",
    "        cur_pred = imio.imread(\"Underwater Image Enhancement/RGHS/OutputImages/pic\" + str(i) + \"_RGHS.jpg\")\n",
    "        \n",
    "        #init_usiqe.append(UCIQE(cur_init))\n",
    "        pred_usiqe.append(UCIQE(cur_pred))\n",
    "        \n",
    "        #init_uiqm.append(getUIQM(cur_init))\n",
    "        pred_uiqm.append(getUIQM(cur_pred))\n",
    "        \n",
    "        #init_cff.append(CFF(cur_init))\n",
    "        pred_cff.append(CFF(cur_pred))\n",
    "    \n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Init USIQE:\",np.mean(init_usiqe))\n",
    "print(\"Pred USIQE:\", np.mean(pred_usiqe))\n",
    "#print(\"Init UIQM:\", np.mean(init_uiqm))\n",
    "print(\"Pred UIQM:\", np.mean(pred_uiqm))\n",
    "#print(\"Init CFF:\", np.mean(init_cff))\n",
    "print(\"Pred CFF:\", np.mean(pred_cff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#init_usiqe = []\n",
    "pred_usiqe = []\n",
    "#init_uiqm = []\n",
    "pred_uiqm = []\n",
    "#init_cff = []\n",
    "pred_cff = []\n",
    "\n",
    "\n",
    "\n",
    "l = [6, 11, 15, 21, 26, 30, 40, 42, 46, 68, 83]\n",
    "for i in range(106):\n",
    "    if(i not in l):\n",
    "        #cur_init = imio.imread(\"ch_real_/ch\" + str(i) + \"_init.jpg\")\n",
    "        cur_pred = imio.imread(\"Underwater Image Enhancement/UCM/OutputImages/pic\" + str(i) + \"_UCM.jpg\")\n",
    "        \n",
    "        #init_usiqe.append(UCIQE(cur_init))\n",
    "        pred_usiqe.append(UCIQE(cur_pred))\n",
    "        \n",
    "        #init_uiqm.append(getUIQM(cur_init))\n",
    "        pred_uiqm.append(getUIQM(cur_pred))\n",
    "        \n",
    "        #init_cff.append(CFF(cur_init))\n",
    "        pred_cff.append(CFF(cur_pred))\n",
    "    \n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Init USIQE:\",np.mean(init_usiqe))\n",
    "print(\"Pred USIQE:\", np.mean(pred_usiqe))\n",
    "#print(\"Init UIQM:\", np.mean(init_uiqm))\n",
    "print(\"Pred UIQM:\", np.mean(pred_uiqm))\n",
    "#print(\"Init CFF:\", np.mean(init_cff))\n",
    "print(\"Pred CFF:\", np.mean(pred_cff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = imio.imread(\"und.jpg\") / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = unet_model(bn = True, pic = True, img_shape=a.shape)\n",
    "model.load_weights(\"nn_weights/exp_new_with_ssim/weights/weights-improvement-0.0451-0.0397.hdf5\")\n",
    "pred= model.predict(a.reshape(1, a.shape[0], a.shape[1], a.shape[2]).astype(np.float32), batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imio.imwrite(\"out_und.jpg\", np.uint8(pred[0, :, :, :] * 255))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [6, 11, 15, 21, 26, 30, 40, 42, 46, 68, 83]\n",
    "for i in range(106):\n",
    "    if(i not in l):\n",
    "        a = imio.imread(\"ch_real_new_with_ssim/ch\" + str(i) + \"_pred.jpg\")\n",
    "        b = imio.imread(\"ch_real_new_with_ssim/ch\" + str(i) + \"_x.jpg\")\n",
    "        c = imio.imread(\"real_by_HE/pic\" + str(i) + \"_HE.jpg\")\n",
    "        d = imio.imread(\"real_by_K_He/pic\" + str(i) + \"_dehazed.jpg\")\n",
    "        \n",
    "        imio.imwrite(\"real_our_He_KHe/pic\" + str(i) + \"_our.jpg\", a)\n",
    "        imio.imwrite(\"real_our_He_KHe/pic\" + str(i) + \"_x.jpg\", b)\n",
    "        imio.imwrite(\"real_our_He_KHe/pic\" + str(i) + \"_HE.jpg\", c)\n",
    "        imio.imwrite(\"real_our_He_KHe/pic\" + str(i) + \"_KHe.jpg\", d)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
